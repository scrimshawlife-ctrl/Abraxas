<div align="center">

# ğŸœ Abraxas

### Deterministic Symbolic Intelligence & Linguistic Weather System

*Provenance-embedded compression detection, memetic drift analysis, and self-healing infrastructure for edge deployment*

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Node.js 18+](https://img.shields.io/badge/node-18+-green.svg)](https://nodejs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.6-blue)](https://www.typescriptlang.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

[Quick Start](#-quick-start) â€¢ [Architecture](#-architecture) â€¢ [Features](#-features) â€¢ [Documentation](#-documentation) â€¢ [Project Status](#-project-status)

</div>

---

## ğŸ¯ What is Abraxas?

**Abraxas** is a production-grade symbolic intelligence system that detects linguistic compression patterns, tracks memetic drift, and operates as an always-on edge appliance with self-healing capabilities.

Think of it as a **weather system for language** â€” detecting when symbols compress ("eggcorns" like "apex twin" â†’ "aphex twin"), tracking affective drift, and generating deterministic provenance for every linguistic event.

### Core Capabilities

- **ğŸ”¬ Symbolic Compression Detection (SCO/ECO)** â€” Detect and quantify when opaque symbols are replaced with semantically transparent substitutes
- **ğŸŒ¦ï¸ Weather Engine** â€” Transform linguistic events into memetic weather patterns and drift signals
- **ğŸ¤– Always-On Daemon** â€” Continuous data ingestion via Decodo API with chat-like interaction interface
- **ğŸ›¡ï¸ Self-Healing Infrastructure** â€” Drift detection, watchdog monitoring, and atomic updates with rollback
- **âš¡ Orin-Ready Edge Deployment** â€” Optimized for NVIDIA Jetson Orin with systemd integration
- **ğŸ”’ Provenance-First Design** â€” Every event includes SHA-256 hash for reproducibility and auditability

---

## ğŸš€ Quick Start

### Prerequisites

```bash
# System requirements
- Python 3.11+
- Node.js 18+
- (Optional) NVIDIA Jetson Orin for edge deployment
```

### Installation

```bash
# Clone repository
git clone https://github.com/scrimshawlife-ctrl/Abraxas.git
cd Abraxas

# Install Python dependencies
pip install -e .

# Install Node.js dependencies
npm install

# Run system diagnostic
abx doctor
```

### Run Your First Analysis

```bash
# Analyze text for symbolic compression
python -m abraxas.cli.sco_run \
  --records tests/records.json \
  --lexicon tests/lexicon.json \
  --out events.jsonl \
  --domain music

# Start the always-on daemon
abx ui

# Start continuous ingestion (requires Decodo credentials)
abx ingest
```

### Development Server

```bash
# Start TypeScript development server
npm run dev

# Run tests
npm test
pytest tests/
```

---

## ğŸ—ï¸ Architecture

Abraxas operates as a **multi-layer stack** combining Python linguistic analysis with TypeScript orchestration:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ABRAXAS ECOSYSTEM                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  TypeScript/Express Layer (Node.js)                      â”‚  â”‚
â”‚  â”‚  â€¢ API Routes & Express Server                           â”‚  â”‚
â”‚  â”‚  â€¢ Weather Engine Integration                            â”‚  â”‚
â”‚  â”‚  â€¢ Chat UI & Admin Handshake                             â”‚  â”‚
â”‚  â”‚  â€¢ Task Registry & ERS Scheduling                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                   â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Python SCO/ECO Core                                     â”‚  â”‚
â”‚  â”‚  â€¢ Symbolic Compression Operator                         â”‚  â”‚
â”‚  â”‚  â€¢ Phonetic & Semantic Analysis                          â”‚  â”‚
â”‚  â”‚  â€¢ Transparency Index (STI) Calculation                  â”‚  â”‚
â”‚  â”‚  â€¢ Replacement Direction Vector (RDV)                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Orin Boot Spine (Edge Infrastructure)                   â”‚  â”‚
â”‚  â”‚  â€¢ Drift Detection & Health Monitoring                   â”‚  â”‚
â”‚  â”‚  â€¢ Overlay Lifecycle Management                          â”‚  â”‚
â”‚  â”‚  â€¢ Atomic Updates with Rollback                          â”‚  â”‚
â”‚  â”‚  â€¢ Systemd Integration                                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Data Layer                                              â”‚  â”‚
â”‚  â”‚  â€¢ Decodo Web Scraping API Integration                  â”‚  â”‚
â”‚  â”‚  â€¢ SQLite Storage with Provenance                        â”‚  â”‚
â”‚  â”‚  â€¢ JSONL Event Persistence                               â”‚  â”‚
â”‚  â”‚  â€¢ AAlmanac Ledger                                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **SCO/ECO Stack** | Python | Linguistic compression detection & analysis |
| **Weather Engine** | TypeScript | Memetic drift pattern generation |
| **Orin Spine** | Python | Edge deployment infrastructure |
| **Chat UI** | Express/React | Admin interface & module discovery |
| **Ingestion Engine** | Python | Continuous data acquisition via Decodo |
| **Self-Healing Layer** | Python/Systemd | Watchdog, drift detection, atomic updates |

---

## âš¡ Features

### Symbolic Compression Detection

Detect when language users compress symbols while preserving intent:

- **ECO_T1 (Eggcorn)** â€” High phonetic similarity (â‰¥0.85) + semantic transparency delta (â‰¥0.18)
- **SCO_T2 (General Compression)** â€” Moderate thresholds with provenance tracking
- **Metrics** â€” STI, CP, IPS, SLC, RDV with deterministic scoring

Example detected event:
```json
{
  "tier": "ECO_T1",
  "original_token": "aphex twin",
  "replacement_token": "apex twin",
  "compression_pressure": 1.42,
  "symbolic_transparency_index": 0.45,
  "rdv": {
    "humor": 0.0,
    "intimacy": 0.6,
    "irony": 0.0
  }
}
```

### Weather Engine Integration

Transform compression events into memetic weather patterns:

- **Symbolic Drift** â€” Intensity of symbol replacement
- **Transparency Flux** â€” Rate of semantic clarification/obscuration
- **RDV Tracking** â€” Humor, aggression, authority, intimacy, nihilism, irony
- **Compression Stability** â€” Eggcorn formation rate

### Always-On Daemon

Run Abraxas as a persistent service:

- **Continuous Ingestion** â€” Scheduled scraping via Decodo API
- **Chat Interface** â€” LLM-like interaction with module discovery
- **Admin Handshake** â€” Dynamic capability detection
- **SQLite Storage** â€” Provenance-stamped document persistence

### Self-Healing Infrastructure

Production-grade reliability for edge deployment:

- **Drift Detection** â€” Git SHA, config, assets, dependencies tracking
- **Watchdog** â€” Automatic service restart on health check failures
- **Atomic Updates** â€” Zero-downtime deployments with rollback
- **Systemd Integration** â€” Managed lifecycle for Jetson Orin

---

## ğŸ“‹ Project Status

### âœ… Completed

- [x] **SCO/ECO Core** â€” Full symbolic compression detection pipeline
- [x] **Orin Boot Spine** â€” Edge infrastructure scaffolding
- [x] **TypeScript Integration** â€” Express API bridge to Python stack
- [x] **Weather Engine** â€” Signal transformation and narrative generation
- [x] **Always-On Daemon** â€” Ingestion engine and chat UI
- [x] **Self-Healing Layer** â€” Drift detection, watchdog, atomic updates
- [x] **Systemd Services** â€” Production deployment units

### ğŸš§ In Progress

- [ ] **Real LLM Integration** â€” Replace stub chat engine with local/remote LLM
- [ ] **UI Dashboard** â€” React components for weather visualization
- [ ] **Expanded Lexicons** â€” Domain-specific compression dictionaries
- [ ] **PostgreSQL Migration** â€” Scale beyond SQLite for production
- [ ] **WebSocket Integration** â€” Real-time compression event streaming

### ğŸ¯ Roadmap

- [ ] **Oracle Pipeline** â€” Daily oracle generation from drift signals
- [ ] **Ritual System** â€” Rune-based symbolic modulation
- [ ] **Multi-Domain Analysis** â€” Crypto, idiom, slang, technical jargon
- [ ] **Event Correlation** â€” Cross-domain drift pattern detection
- [ ] **Mobile UI** â€” Edge device management interface

### ğŸ“Š Recent Updates

See recent pull requests and commits:
- **#8** â€” Integrate Operator Auto-Synthesis (OAS) into Abraxas Slang System
- **#7** â€” Add always-on Abraxas daemon with Decodo ingestion and chat UI
- Pydantic dependency and OAS module integration
- Self-healing layer with watchdog and atomic updates

---

## ğŸ“– Documentation

### Core Modules

- **[SCO Stack](README_SCO.md)** â€” Symbolic Compression Operator documentation
- **[Orin Spine](README_ORIN.md)** â€” Edge deployment and infrastructure
- **[Integration Guide](INTEGRATION_SCO.md)** â€” TypeScript/Python integration
- **[Deployment Guide](DEPLOYMENT_SCO.md)** â€” Production deployment

### CLI Reference

```bash
# Orin commands
abx doctor          # System diagnostics
abx up              # Start HTTP server
abx smoke           # Run deterministic smoke test
abx assets sync     # Generate asset manifest
abx overlay list    # List installed overlays
abx drift check     # Check for configuration drift
abx watchdog        # Start health monitoring
abx update          # Atomic update with rollback
abx ingest          # Start data ingestion
abx ui              # Start chat UI server
abx admin           # Print admin handshake JSON

# SCO analysis
python -m abraxas.cli.sco_run --records <file> --lexicon <file> --out <file>
```

### API Endpoints

```bash
# Health checks
GET  /healthz              # Liveness
GET  /readyz               # Readiness with provenance

# SCO analysis
POST /api/sco/analyze      # Run compression detection
POST /api/sco/weather      # Generate weather signals
GET  /api/sco/lexicons     # List available lexicons

# Chat UI
GET  /admin/handshake      # Discover modules
POST /chat                 # Send messages
GET  /data/latest          # Inspect ingested data
```

---

## ğŸ”§ Configuration

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `ABX_ROOT` | `/opt/aal/abraxas` | Root installation directory |
| `ABX_PROFILE` | `orin` | Runtime profile (orin/dev) |
| `ABX_PORT` | `8765` | HTTP server port |
| `ABX_UI_PORT` | `8780` | Chat UI port |
| `ABX_DB` | `.aal/state/abx.sqlite` | SQLite database path |
| `DECODO_AUTH_B64` | (required) | Decodo API credentials |

### Systemd Services

For production deployment on Jetson Orin:

```bash
# Core services
sudo systemctl enable abraxas-core
sudo systemctl enable abx-ingest
sudo systemctl enable abx-ui
sudo systemctl enable abx-watchdog
sudo systemctl enable abx-update.timer

# Check status
sudo systemctl status abraxas-core abx-ingest abx-ui
```

---

## ğŸ§ª Testing

```bash
# Python tests
pytest tests/

# TypeScript tests
npm test
npm run test:coverage

# Smoke test (deterministic)
abx smoke

# E2E test
curl -X POST http://localhost:5000/api/sco/analyze \
  -H "Content-Type: application/json" \
  -d '{"texts": ["I love Aphex Twins"], "domain": "music"}'
```

---

## ğŸ¤ Contributing

Contributions welcome! This project follows deterministic, provenance-first design principles:

1. All changes must pass `abx smoke` deterministic tests
2. Include SHA-256 provenance for new linguistic events
3. Maintain backward compatibility for API endpoints
4. Follow existing code style (TypeScript/Python)

---

## ğŸ“„ License

MIT License â€” See [LICENSE](LICENSE) file for details.

---

## ğŸ”— Links

- **GitHub**: [scrimshawlife-ctrl/Abraxas](https://github.com/scrimshawlife-ctrl/Abraxas)
- **Issues**: [Report bugs or request features](https://github.com/scrimshawlife-ctrl/Abraxas/issues)
- **Decodo API**: [Web Scraping API](https://decodo.com)

---

<div align="center">

**Built for deterministic symbolic intelligence at the edge**

*Abraxas â€¢ Where language becomes weather*

</div>
